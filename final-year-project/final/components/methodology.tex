% !TEX root = ../final_report.tex
\section{Methodology}
\label{sec:methodology}
This section aims to give the reader an insight into the process used to build the application. After reading this section the reader should have a clear understanding of all methodologies used and how they benefited the project.

\subsection{Agile}
\label{sub:agile}
The Agile movement helps teams develop in unpredictable circumstances by using incremental and iterative units of work. It provides a mechanism by which feedback is not only facilitated but actively encouraged, promoting greater transparency along the development cycle \citep{Agile2016}.

Agile was chosen as the development methodology for this project for the following reasons:

\paragraph{Quality Testing} Testing is integrated into the development cycle, enabling the developer to continuously monitor the functionality and performance of the application. In Waterfall, testing is not carried out until the end when development is finished. This can lead to problems for a single developer as testing coverage and quality may not be as high. 

\paragraph{Visibility} Agile provides a great environment to see how expectations are managed effectively. It provides a clear view into the project scope and the current track it is on. With Waterfall all expectations and deliverables need to be forecast before any development begins. This can be difficult to do and can mean increased overhead of work.

\paragraph{Risk Management} Incremental development cycles allow the developer to accurately assess any challenges in the early stages of developement and make it easier to respond and adapt. In Waterfall there is very little room for adapting to unforeseen challenges.

\paragraph{Flexibility} Agile allows for change natively. Instead of setting a rigid time plan up front the timescale is set and each \gls{sprint} allows for the requirements to change and for more to emerge as development continues.

Agile uses time-boxed units throughout the development cycle \citep{Agile2016}. These are short development cycles designed to give the developer achievable goals while also allowing for change at short intervals.

The Agile implementation used in this project will be discussed further in Section \ref{sec:implementation}.

\subsubsection{Scrum}
Agile is an umberella methodology with several flavoured implementations. One of the most popular, \gls{Scrum}, is the methodology followed by a large proportion of Agile teams and also the chosen methodology of the Red Hat team. As such, this project adopted a hybrid \gls{Scrum} Methodology, tweaked to suit the needs of a single person project. The elements of Scrum that were chosen or modified include:

\begin{enumerate}
	\item Backlog Grooming - Each \gls{sprint} has a \gls{sprint} planning session to initially scope the product \gls{backlog} and to inform the total scope of the project. This typically involves the product owners who will help to shape the overall project direction by providing their priorities for the project.
	\item Sprint Planning - Refining the \gls{backlog} to break large development tasks into smaller tasks which will fit better in a \gls{sprint}. This also helps to identify similar tasks which can be grouped together and reduce duplication.
	\item Sprint - All development work is carried out here. There are daily stand ups which involve the developer taking into account the work achieved the previous day, what was going to be achieved today and also any difficulties encountered. While this project was a lone developer project it was still constructive as it forced consideration of the Jira board and also helped guide the day to day work.
	\item Sprint Review - After a \gls{sprint} is completed a \gls{sprint} review is then performed which will evaluate goals achieved versus goals planned and the \gls{backlog} is then re-prioritised accordingly.
	\item Sprint Retrospective - A retrospective will then analyse \gls{sprint} performance and help to highlight areas where improvement can be made. This will also enhance the accuracy of the next \gls{sprint}.
\end{enumerate}

\begin{figure}[!ht]
\centering
\includegraphics*[width=\textwidth]{images/scrum_process}
\caption{\em Agile/Scrum Process}
\label{fig:agile}
\end{figure}

To evaluate all tasks on the backlog a popular method of `story points' was used. This involves the developer rating tasks based on estimated effort. It uses the Fibonacci numbers as a guide and all tasks should be relative to each other. It is not an exact science but does provide a way of judging the amount of work remaining. For example when it is well established that a backlog item with a story point rating of 2 may take a day to complete then it is reasonable to assume an item with a rating of 3 may take a day and a half to complete.

The following roles were also identified within this project:

\begin{itemize}
	\item Product Owner - Leigh Griffin (Red Hat)
	\item Scrum Master - Dr. Brenda Mullally
	\item Scrum Team/Developer - Stephen Coady
\end{itemize}

\subsection{Jira}
\label{sub:jira}
The project management tool Jira was used to aid with Agile implementation and to track all project activity \citep{JBoss2016}. Jira is a professional grade project management software used by companies to execute a distributed version of agile. It provides functionality to graphically manage the product backlog and each \gls{sprint}. The developer is presented with a dashboard which allows them to create and edit tasks by assigning descriptions, subtasks and estimation of work.

Granular control over backlog items is important in an Agile environment as change is expected and so being able to have fine-grained control over everything makes this process much easier.

\subsection{Gitflow}
\label{sub:gitflow}
As this project will be developed in an open source environment there will also be well defined procedures followed when using \gls{git} as a version control tool. This ensures that should any other developers wish to contribute to the project in the future then a set of guidelines will ensure all code is merged in a clean way which will in turn ensure complete transparency. This set of guidelines is referred to as a `Gitflow'. The Gitflow used for this project can be seen below in Figure \ref{fig:gitflow}.

\begin{figure}[!ht]
\centering
\includegraphics*[width=0.8\textwidth]{images/gitflow}
\caption{\em Gitflow \citep{Driessen2010}}
\label{fig:gitflow}
\end{figure}

Using a well-defined Gitflow provides many benefits. Namely:

\subparagraph{Tagged Versions}\mbox{}\\
Tagging versions at release intervals means it is easy to see a desired version if the developer wishes to do so. For example if someone wishes to download a version 0.6.0 of software then they can navigate to the versions pane in \gls{github} and easily download that specific version. An example of this for this project can be seen in Figure \ref{fig:git_tags}. Here it shows how a developer can easily download a specific version.

\begin{figure}[!ht]
\centering
\includegraphics*[width=0.7\textwidth]{images/git_tags}
\caption{\em Git Tagged Versions}
\label{fig:git_tags}
\end{figure}

\subparagraph{Safe Merges}\mbox{}\\
When using multiple branches it can become difficult to safely merge code from two branches. Having a well-defined process to do this minimises this risk while also creating a clearer picture in the developer's mind about what code is being merged and where it is being merged.

\subparagraph{Easier Troubleshooting}\mbox{}\\
In the case where something has gone wrong if there is a reproducible set of steps which were followed then troubleshooting the Git environment becomes easier. It also makes it easier for novice developers who may be inexperienced with Git to contribute to the project if every step is documented.

\subsection{Testing}
\label{sub:testing}
Testing is a vital aspect of software development. It is for that reason that great consideration was given to the test plan for this application. Software testing in this project has been broken up into 4 distinct headings, namely:

\begin{itemize}
	\item Unit Testing
	\item Integration Testing
	\item System Testing
	\item Acceptance Testing
\end{itemize}

Unit, integration and system testing in this project is all automated while acceptance testing is a manual process. Each of these will now be discussed whilst describing how they are implemented in this project in detail.

\paragraph{Unit Testing}\mbox{}\\
Unit tests are the most basic form of automated testing and occur when one unit of a program is tested. This unit may be a basic variable or it can also be a function belonging to a module of software. Unit tests on a function for example may call that function and compare the returned value with the expected output. It is a simple standalone test which does not rely on any other test within the test suite \citep{UnitTesting2017}. An example of a unit test for this project can be seen in Figure \ref{fig:unit_test}.

\begin{figure}[!ht]
\begin{lstlisting}
	it('should list specific container', (done) => {
		request(app)
			.get('/api/containers/' + testContainer)
			.set('x-access-token', token)
			.expect('Content-Type', /json/)
			.end(function(err, res) {
				expect(res.status).to.be.equal(200);
				assert.equal(testContainer, res.body.container.Id);
				done();
			});
	}); 
\end{lstlisting}
\caption{\em A Simple Unit Test}
\label{fig:unit_test}
\end{figure}

We can see on line 8 of Figure \ref{fig:unit_test} that this unit test simply makes an \gls{API} call and compares the result to the expected result. While this is powerful it is also too simple for modern day applications. Instead, we must test how several different functions acting in sequence behave, as this gives a more realistic simulation of an application being used by a real user.

\paragraph{Integration Testing}\mbox{}\\
We therefore naturally arrive at integration tests as a means to increase testing potency. Integration tests are essentially a sequence of unit tests. This sequence is carried out with the express intent of exposing defects in software as a result of the interaction between multiple components \citep{IntegrationTesting2017}.

\begin{figure}[!ht]
\begin{lstlisting}
	it('container should be stopped', (done) => {
      request(app)
        .get('/api/containers/' + testContainer)
        .set('x-access-token', token)
        .expect('Content-Type', /json/)
        .end(function(err, res) {
          expect(res.status).to.be.equal(200);
          assert.equal("exited", res.body.container.State.Status);
          done();
        });
    });

    it('container should restart', (done) => {
      request(app)
        .post('/api/containers/' + testContainer + '/restart')
        .set('x-access-token', token)
        .expect('Content-Type', /json/)
        .end(function(err, res) {
          expect(res.status).to.be.equal(200);
          expect(res.body.message).to.equal("Container restarted successfully");
          done();
        });
    });
\end{lstlisting}
\caption{\em A Simple Integration Test}
\label{fig:integration_test}
\end{figure}

\clearpage

We can see a trivial example of integration testing in this project in Figure \ref{fig:integration_test}. In this test case, we first stop the container and then restart it before checking that the container is actually started. This is to ensure that the act of stopping the container does not interfere with restarting.


\paragraph{System Testing}\mbox{}\\
System testing is the act of testing a system in its entirety and in the same environment on which it will run \citep{SystemTesting2017}. This will be discussed further in Section \ref{sub:ci_cd} but for the purposes of this section system testing refers to the process of all tests being in sequence and those tests should cover the complete application. This is referred to as \gls{code coverage} and will again be discussed further in Section \ref{sub:code_quality}. 

\paragraph{Acceptance Testing}\mbox{}\\
Acceptance testing is the process of manually using an application to ensure it meets requirements and performance expectations \citep{AcceptanceTesting2017}. Since this project has a product owner in the shape of Red Hat Mobile they acted as the user. At the end of each sprint this involved the product owner using a staged version of the application to ensure it met all of their initial requirements for the newly developed feature(s). 

At the end of the project the user acceptance testing was carried out by product owner Dr. Leigh Griffin (Red Hat). This involved creating a ticket on Jira which was composed of sub tickets. Each of these sub tickets was then matched against one high level initial requirement of the project. These tickets were then assigned to the product owner and a detailed check was carried out ensuring all requirements were met. This testing plan can be found at \url{https://issues.jboss.org/browse/FH-3496} and the final sign off sheet signed by both the developer and then product owner can be seen in Figure \ref{fig:UAT}.

\clearpage

\begin{figure}[!ht]
\centering
\includegraphics*[width=0.8\textwidth]{images/UAT}
\caption{\em User Acceptance Test Sign Off Sheet}
\label{fig:UAT}
\end{figure}

\subsection{Code Quality/Coverage}
\label{sub:code_quality}
It is vital in any project to keep code quality at a high standard. If the project wishes to attract other developers to contribute then a good codebase with current best practices implemented and few bugs will help. To do this the tool SonarQube will be used, as discussed in Section \ref{sub:sonarqube-technologies}. SonarQube will scan the codebase and inform the developer of any \gls{code smell}s present and will also perform calculations such as \gls{technical debt} and \gls{code coverage}. 

SonarQube is embedded in the \gls{ci} pipeline for this project. This will ensure that code is consistently monitored which in turn ensures code quality and test coverage is always at the forefront of the developers mind. The SonarQube repository for this project can be found in Appendix \ref{appendix:sonarqube}.

\subsection{Continuous Integration/Deployment}
\label{sub:ci_cd}
In software development, \gls{ci} is the act of continuously ensuring software is of a suitable standard to be integrated into the current software package. This will ensure that any changes made to the code base will receive immediate test-feedback \citep{Fowler2006}. Even though this application was not built in a production environment, having a continuous build cycle ensured maximum quality code and also reduced the risk of a ``bug bottleneck''. \Gls{cd} is the act of making an application available for use as soon as it has passed all tests contained in the integration section of the build pipeline.

For this project, a complete pipeline was built to facilitate a full continuous integration \& deployment environment build and release process. This pipeline consists of the following:

\begin{itemize}
	\item \gls{git} repository to house the code (stored remotely on \gls{github})
	\item \gls{Travis} CI build server to execute tests and carry out post-test tasks
	\item \gls{sonarqube} Server to analyse and advise of improvement to code, based on best-practices
	\item \gls{dockerhub} repository which the built image is pushed to
	\item A \gls{staging server} which the built image is deployed to and then run on
\end{itemize}

This pipeline can be seen in Figure \ref{fig:CICD} and will work as follows:

\begin{enumerate}
	\item Git commit is made
	\item Travis CI build is triggered which runs all tests and \gls{code coverage} reports
	\item If successful a SonarQube push is triggered and the code is sent for evaluation
	\item Once this is complete Travis then builds a \gls{Docker image} from the newly passed code. This image is then pushed to the associated \gls{dockerhub} repository to be made public
	\item Once the push is complete Travis then deploys the application (by running a container) on the \gls{staging server}.
	\item Travis then pushes a notification to the developer to inform of success/failure status
\end{enumerate}

\begin{figure}[!ht]
\centering
\includegraphics*[width=\textwidth]{images/CI_CD}
\caption{\em Continuous Integration and Deployment Pipeline}
\label{fig:CICD}
\end{figure}

There are several advantages to this method of integration and deployment which are additional to those mentioned previously. These are as follows:

\begin{itemize}
	\item The process is completely automated, meaning one git push is all that is required to fully build the application and make it ready for deployment.
	\item Using SonarQube as part of the integration pipeline means that code quality does not drop at any iteration of development.
	\item Automatically releasing to DockerHub will also mean that the application is rapidly updated between software releases.
	\item Staging the application provides immediate feedback for anybody wishing to evaluate the current iteration of the project and whether or not it has met the requirements for the sprint.
\end{itemize} 

\subsection{Twelve Factor Application}
A recent methodology has emerged regarding web applications and the development best practices associated with creating and deploying them. This methodology is known as `The Twelve-Factor App' and dictates the guidelines to follow for an application to be easily setup, portable and suitable for deployment on various architectures \citep{Wiggins2017}. An examination of each of these twelve factors will now be completed and will include how they were applied during the development of Gantry.

\paragraph{1. Codebase}\mbox{}\\
\textit{`One codebase tracked in revision control, many deploys'}

Gantry is tracked in a single \gls{git} repository. It is not a deployable application in the traditional sense as each developer must deploy their own version of this application.

\paragraph{2. Dependencies}\mbox{}\\
\textit{`Explicitly declare and isolate dependencies'}

All external dependencies in this project such as NPM modules, \gls{CSS} files and external libraries are bundled within the application. Gantry can be run without an internet connection and only external API calls will fail.

\paragraph{3. Config}\mbox{}\\
\textit{`Store config in the environment'}

While there is very little config in this application it is isolated to a config file and is not hard-coded within the application.

\paragraph{4. Backing Services}\mbox{}\\
\textit{`Treat backing services as attached resources'}

The only backing service within this application is the Nedb database and it is treated as a modular service which satisfies this factor.

\paragraph{5. Build, Release, Run}\mbox{}\\
\textit{`Strictly separate build and run stages'}

As this application uses Docker as both a build and deployment vehicle there is a clear separation by default here. The image is built, the container is deployed and they are both separate entities.

\paragraph{6. Processes}\mbox{}\\
\textit{`Execute the app as one or more stateless processes'}

Again Docker solves this problem as it completely isolates the environment and therefore the process.

\paragraph{7. Port Binding}\mbox{}\\
\textit{`Export services via port binding'}

This whole application is exposed via a single port listening on the host.

\paragraph{8. Concurrency}\mbox{}\\
\textit{`Scale out via the process model'}

This factor is not applicable to this application as the process to run this application is already a single unit and cannot be broken down any further. This factor deals with applications which may have multiple instances of themselves running across several hosts.

\paragraph{9. Disposability}\mbox{}\\
\textit{`Maximize robustness with fast startup and graceful shutdown'}

Due to the ephemeral nature of \gls{Docker container}s this constraint is also satisfied. Containers can be stopped, removed and quickly started again without affecting the next instance's startup or shutdown procedures.

\paragraph{10. Dev/Prod Parity}\mbox{}\\
\textit{`Keep development, staging, and production as similar as possible'}

This factor is implemented by using Vagrant as discussed in Section \ref{sub:vagrant} for the development environment to replicate the Docker engine environment. The \gls{ci} server Travis is then used with the same Docker engine. As any user running the application will also be using the Docker engine it ensures the application will always have the same environment available to it.

\paragraph{11. Logs}\mbox{}\\
\textit{`Treat logs as event streams'}

This application exports all application logs directly to the web application. This ensures they are always available to the user if required.

\paragraph{12. Admin Processes}\mbox{}\\
\textit{`Run admin/management tasks as one-off processes'}

This application does not provide the facility to run any administrative tasks.

We can see that by choosing to use Docker as a build and deployment vehicle many of these twelve factors have been automatically satisfied with minimal input from the developer.

\subsection{Documentation}
This section will discuss the tools used to document the entire process of building this application and also the document which accompanies it.
\subsubsection{User Documentation}
Since the project comes in two parts, the standalone API and the user web application there are technically two separate user guides. The first user guide is relatively short and can be seen in Appendix \ref{appendix:code}. It is the form of the README file associated with the repository. In the open source community it is common practice to include everything in the README which the user requires to begin using the application. 

The second set of user documentation uses a standalone application called Swagger UI to document the API \citep{Swagger2017}. Swagger allows any user to interact with the API through the documentation. For example, anyone with access to the documentation can make calls to the real API by filling in data and pushing buttons. It shows the user all current API endpoints and what each accepts as parameters and returns as a result. A screenshot of this can be seen below in Figure \ref{fig:swagger-overview}. 

\begin{figure}[!ht]
\centering
\includegraphics*[width=\textwidth]{images/swagger-overview}
\caption{\em Swagger Overview}
\label{fig:swagger-overview}
\end{figure}

An example of how one individual API endpoint is shown in Swagger in Figure \ref{fig:swagger-individual}.
\clearpage

\begin{figure}[!ht]
\centering
\includegraphics*[width=\textwidth]{images/swagger-individual}
\caption{\em A Single Swagger Endpoint}
\label{fig:swagger-individual}
\end{figure}

\paragraph{Making it accessible}\mbox{}\\
To make the documentation easily accessible to anybody who wishes to view it it has been embedded as part of the application. When the user runs the project the node application automatically serves the documentation up on the same host as the application. This can be seen by following the documentation link in Appendix \ref{appendix:staging}.

\subsubsection{LaTeX}
Latex is a software package which is used to write academic, high-quality papers. It is written using plain text with some markup which is then used to format. The plain text documents are compiled and Latex produces a pdf file \citep{Latex2017}.

In this project Latex was used exclusively to write this document. This offered a number of clear benefits over traditional office-based software packages.

\begin{itemize}
	\item Plain text - since Latex only uses plain text to create its documents the writer is free to concentrate on the important aspects of writing documentation.
	\item Source controlled - again as Latex is plain text it can be easily stored in a version control system such as \gls{git}.
	\item Powerful compilation engine - The compilation engine behind Latex offers huge benefits such as auto-referencing all sections and figures etc. It can also auto-create sections such as glossaries and tables of contents.
\end{itemize}

The source code used to create this report can be seen in Appendix \ref{appendix:reports} and will be made available as a template for future WIT students to use.
