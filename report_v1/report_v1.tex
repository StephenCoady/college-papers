\documentclass{article}

%-----------------------------------------------PACKAGES-------------------------------------------------------------%
\usepackage{graphicx} %images
\DeclareGraphicsExtensions{.pdf,.png,.jpg} % configures latex to look for the following image extensions
\usepackage{setspace} % allows for configuring the linespacing in the document
\usepackage{caption}
\usepackage{natbib}
\usepackage{appendix}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage[explicit]{titlesec}
\usepackage{hyperref}
\usepackage[nottoc,numbib]{tocbibind}
\usepackage[parfill]{parskip}
\usepackage{listings}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\bibliographystyle{agsm}
\setcitestyle{authoryear,open={(},close={)}}

\begin{document}
\onehalfspacing
\tableofcontents
\newpage
\section{Project Overview}
\subsection{Problem}
\label{sub:problem}
Currently, container lifecycle management is predominantly achieved through the command line. This means that managing images, running containers and managing their interactions with each other can all be time-consuming tasks. One way in which this is aided is by the use of scripts. While this is useful, it does also mean that the user must be comfortable with the command line to manage the containers.

Managing containers can quickly become a tedious and error-prone task when the number of containers starts to grow. In a production system it can mean provisioning and managing dozens of containers and their dependencies. This, coupled with the fact that the container must be managed not just at start up but over its complete lifecycle, means that the advantage of using containers can quickly be negated by their lifecycle management.

\subsection{Industry Example}
\label{sub:industry}
As a real-life example, Red Hat Mobile's Application platform is made up of between 20-25 Docker images. So in a development environment that means that running all of those images gives around the same number of containers to manage. While this is no small feat, it can be mitigated by things like scripts, Docker Compose etc. However when we start running these containers in production that number can quickly grow, depending on resiliency and load requirements. At this point it is now a much larger task to manage all of these containers. 

Red Hat Mobile also employ a Continuous Integration/Deployment (CI/CD) model when it comes to their software. Whenever a pull request is opened for a component of their application, it triggers a CI build, which in turn (depending on whether it passes or not) can trigger a build of a Docker image related to this component. So essentially for each Docker image there may be many tagged versions of that image built and ready to be used. This process could be aided by a visual component to view and inspect these images.


\subsection{Solution}
With the aim of solving the problem described in Sections \ref{sub:problem} and \ref{sub:industry}, the overall goal is to provide a tool to aid with the management of a container's lifecycle. In other words, the end product of this project will aim to tie together the basic container and image controls to build one cohesive management unit. This unit will allow for a graphical information panel and console to carry out any tasks needed.

It will aim to provide a means to remotely manage a server and orchestrate the containers and container images on that instance, therefore greatly reducing the overhead in management of that server.

\subsection{Goals}
In terms of goals of the project, the core or primary goals can be broken up into functional and non-function goals as follows:

\subsubsection{Functional}

\begin{itemize}
  \item Image Manipulation/Control
  \item Container Manipulation/Control
  \item Remote Control of the application through an API
  \item View Running statistics of containers
  \item Search Docker Hub/Private Registry 
\end{itemize}
\mbox{}\\
These are the minimum goals which will solve the problem discussed in Section \ref{sub:problem}. Some stretch goals, which may prove too large to fit into the project are:
\mbox{}\\
\begin{itemize}
  \item Mobile Application
  \item Having the final application itself run within a container
  \item Connecting to multiple servers running the application at once
  \item CI/CD Integration
\end{itemize}
\mbox{}\\
Although these goals are not deemed immediately important and potentially undeliverable it is still important to keep them on the backlog. We will look at the reason for this in Section \ref{subs:agile}.

\subsubsection{Non-Functional}

\paragraph{Testing}\mbox{}\\
This project will aim to deliver a product with extensive unit tests. It will follow the behavioral driven development (BDD) method which will ensure code is hardened and minimize the amount of bugs. This will also mean greater development speed as code will be re-usable with greater efficiency. This is discussed further in section \ref{subs:support}.

\paragraph{Security}\mbox{}\\
The end product will also be secure. The Docker daemon needs to run on a host with root privileges, which can have disastrous affects for the host if not managed correctly. Since this application will effectively allow remote control of this daemon it is important that only a trusted user be allowed to use the application. 

\paragraph{Scalability}\mbox{}\\
When the application can run on a server and allow the containers on that server be controlled it is a very useful application. However, in industry it is rarely just one server housing the application. For this reason the end product of this project will need to scale \textit{with} the server it is managing. To achieve this the application will need to be able to communicate with several servers at once.

\subsubsection{Deliverables}
The deliverables of this project are as follows:

\paragraph{Server-side Application}\mbox{}\\
This is the main part of the application and will act as the controller of the Docker API.

\paragraph{Front-end Application}\mbox{}\\
This will be the interface through which the user will communicate with the server application. It will be exposed through an API to allow for remote calls.

\paragraph{Open Source Node Module}\mbox{}\\
If this project is successful, I intend to release the source code as open source, where it can be built upon and improved by the community.

\paragraph{Containerized Application}\mbox{}\\
Although a stretch goal, a possible deliverable from this project would be to have the whole application running within a container. This would allow for rapid deployment of the application and would also be a huge learning outcome.


\section{Investigation}

\subsection{Methodology}
\label{subs:agile}

The methodology which this project will be carried out under is an important decision. It will have a significant impact on timelines, deliverables and overall product quality. Therefore which methodology to use should be given careful consideration. The guide by \citep{Manifesto2016} was used as reference when making this decision.

The two to be considered are Agile and a more traditional approach, named Waterfall. While both have strengths and weaknesses Agile was chosen for this project as it was deemed a better fit for the following reasons:

\paragraph{Quality Testing} Testing is integrated into the development cycle, enabling the developer to continuously monitor the functionality and performance of the application. In Waterfall testing is not carried out until the very end when development is finished. This can lead to problems for a lone-developer as testing coverage and quality may not be as high. 

\paragraph{Visibility} Agile provides a great environment to see how expectations are managed effectively. It provides a clear view into the project scope and the current track it is on. With Waterfall all expectations and deliverables need to be forecast before any development has begun. This can be difficult to and can mean increased overhead of work.

\paragraph{Risk Management} Incremental development cycles allow the developer to accurately assess any challenges early on and make it easier to respond and adapt. In Waterfall there is very little room for adapting to unforeseen challenges.

\paragraph{Flexibility} Agile allows for change natively. Instead of setting a rigid time plan up front the timescale is set and each sprint allows for the requirements to change and even for more to emerge as development continues.

Agile uses tools called sprints throughout the development cycle \citep{Agile2016}. These are short incremental development cycles which are planned at the beginning of each sprint itself and analyzed at the end.

Each sprint in this project will have a well-defined goal, which will allow for accurate judging of the project scope and whether or not it is on track. As part of the Agile process there will be a planning session to initially scope the product backlog and to inform the total scope of the project. At the end of the initial sprint a sprint review will then be performed which will evaluate goals achieved versus goals planned and the backlog will then be re-prioritized accordingly. A sprint retrospective will then analyze sprint performance and help to highlight areas where improvement can be made. This will also enhance the accuracy of the following sprint.

\subsection{Continuous Integration}
Continuous Integration is the act of continuously ensuring software is of a suitable standard to be integrated into the current software package. This will ensure that any changes made to the code base will receive immediate test-feedback. Even though this application will not be built in a production environment having a continuous build cycle will ensure maximum quality code and also reduce the risk of a ``bug bottleneck'' further down the line.

\begin{figure}[!h]
\centering
\includegraphics*[width=0.8\textwidth]{images/CI}
\caption{\em Continuous Integration}
\label{fig:CI}
\end{figure}

\subsection{Existing Solutions}
Currently there exists several other projects which aim to provide the same solution as this one does. There are, however, subtle differences in either the feature set or implementation of these solutions which validates this project as a worthwhile undertaking. 

\paragraph{Lack of Features}\mbox{}\\
One of these projects ``UI For Docker'', is an open source project written in Golang \citep{UIRepo2016}. It shares the same basic feature set as this project however it does allow for advanced controls such as starting a container from a Dockerfile or searching for new images to start containers from. Also, upon experimentation with UI For Docker the programs error handling and user feedback was not found to be satisfactory. As an example if renaming a container was attempted while it was still running the container would simply crash instead of telling the user it must be stopped first. While I believe that it is an excellent project this combined with the lack of the previously mentioned features means it is not powerful enough to solve the domain problem discussed in Section \ref{sub:problem}. 

\paragraph{Cost}\mbox{}\\
Docker themselves provide a lifecycle management solution, however it comes as a monthly subscription \citep{Docker2016}. It is not currently available to run privately which makes the product rather restricted. While the subscription fee is relatively small it is still a barrier for smaller teams or single developers. Since this project aims to produce an open-source application it is catering for an opening in the market.
sur elook 
\section{Technologies}
\subsection{Node.JS}
Node.js is a server-side JavaScript runtime, it is built on the same V8 engine that powers the popular Chrome browser. It uses an event-driven, non-blocking I/O model that makes it lightweight, efficient and very fast. Node.js' package ecosystem, npm, is the largest ecosystem of open source libraries in the world. \citep{Nodejs.org2016}.

It is node's asynchronous nature which makes it so powerful. Being asynchronous essentially means that it does not create a new thread every time a request needs to be dealt with. Instead, it relies on a single event loop to handle requests which never blocks I/O. This can be seen in Figure \ref{fig:event_loop}.


One benefit of Node using a single event loop is that it is less CPU intensive since it does not need a new thread for every new request. Node is also non-blocking, which when combined with using a single event-loop mean it is very fast.

Some advantages of using Node for this project are:

\begin{itemize}
  \item Large online community - vital for troubleshooting
  \item One of the largest online ecosystems providing a vast amount of third party modules, meaning it will not be necessary to ``re-invent the wheel''
  \item It is Javascript so the code base will not be verbose
\end{itemize}

\begin{figure}[!h]
\centering
\includegraphics*[width=0.6\textwidth]{images/event_loop}
\caption{\em Node Event Loop}
\label{fig:event_loop}
\end{figure}

\subsection{Mongo}
MongoDB is an open source document-oriented database. It is a NoSQL database which means Mongo does not support relationships between tables \citep{Mongo216}. Instead, MongoDB uses JSON-like ``documents'' to store information in an ordered way. This is advantageous for a number of reasons, namely:

\begin{itemize}
  \item Flexibility - Since Mongo does not have relations it is easy to change the database as development continues, without the need for migrations of the current schema.
  \item Javascript - Since the application itself will be written in Node it will be extremely beneficial to have a database which stores its information in JSON.
  \item Simplicity - When a database is schema-less it removes the need for complex actions such as joins, while still providing the power of complex queries.
\end{itemize}

\subsection{Supporting Technologies/Processes}
\label{subs:support}
\paragraph{Vagrant}\mbox{}\\
Vagrant is a development tool to provision and `sandbox' the complete development environment from the host machine it is running on. This is very beneficial, as it means all necessary dependencies can be bundled into one virtual machine and updated or changed when needed. 

Vagrant also allows the developer to standardize all of the different environments the application will run on. This means that if the code will be deployed to a specific version of a specific operating system then the developer can easily replicate this on the local development environment. It allows the developer to build the application on one (local) environment and deploy to the \textit{exact same} remote environment. This is extremely beneficial in terms of code reliability and stability - as the runtime can be reproduced easily.
\paragraph{Ansible}\mbox{}\\
Ansible is a tool to provision virtual machines running locally or remotely. A formal process of all deployment and provisioning will be employed in this project. Meaning that the same route from running code locally to it running on a remote server will always be followed.

Ansible paired with Vagrant in this project will mean any discrepancies or bugs in the code will not be introduced by the environment or the deployment/provisioning process. This is very important as it can reduce the development workload. 

\paragraph{Testing}\mbox{}\\
This project will use third party node modules to perform its unit tests. These unit tests will be behavioral-driven, meaning the components will be tested individually with the end-goal of the passing test being validating a certain behavior of the application, as opposed to validating the functionality of each individual component.

In this way, the project will follow the behavioral driven development (BDD) model. The advantage of this model over pure unit testing in test-driven development (TDD) is that BDD keeps the end result in mind at all times, instead of just the conditions for an individual unit test to pass. This allows the developer to constantly keep in mind the goal of the module being tested.


\newpage
\bibliography{bibliography}

\end{document}
